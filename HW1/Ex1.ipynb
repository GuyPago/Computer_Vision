{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Vision - Fall 2021\n",
    "\n",
    "**Lecturer:** Prof Yael Moses, IDC\n",
    "\n",
    "**TA:** Eyal Friedman, IDC\n",
    "\n",
    "**Submission date: 9.11.21** \\\n",
    "Note: in case you need an extenstion for any reason - you can submit it by 14.11.21.\\\n",
    "No extra extensions will be given.\n",
    "\n",
    "\n",
    "## <span style=\"color:blue\">Exercise 1  </span>\n",
    "\n",
    "In this exercise you will practice basic image operation as loading, saving and displaying an image, getting familiar with 'numpy' and the benefits of vectorized operations in Python. This exercise contains 3 parts:\n",
    "\n",
    "1. Image Convolution.\n",
    "2. Implementing a classic Canny Edge Detector and answering questions.\n",
    "3. Implementing Hough Transform \n",
    "\n",
    "## Submission guidelines:\n",
    "\n",
    "1. Your **zip** should include the following files only:\n",
    "    - ex1.ipynb  (**Or**  ex1.py for students who refuses to work with Jupiter Notebook). \n",
    "    - ex1_ID_ID.pdf (If you decieded not to answer on some of the questions in the notebook, you should submit it as a pdf file). \n",
    "   (Don't add the python code to that file.)\n",
    "4. You may use any IDE as you want (Spyder, Jupyter Notebook, Pycharm, ect.).\n",
    "5. Name the zip file **'ex1_ID_ID.zip'** and **do not** include any additional directories. \n",
    "6. Submit using *moodle*.\n",
    "7. Submit on time!\n",
    "8. You can submit this assignment in pairs (no triplets)\n",
    "- **Important - if you submit in pairs, one should submit the howework and the other should submit a simple text file named: ID_ID.txt and nothing else.**\n",
    "\n",
    "\n",
    "## Read the following instructions carefully:\n",
    "1. Write **efficient vectorized** code. When you think you cannot use vectorized code, give a short explanation why.\n",
    "2. You are responsible for the correctness of your code and should add as many tests as you see fit. Do not submit your tests, unless requested.\n",
    "3. Use `python 3` and `numpy 1.18.5`. Changes of the configuration we provided are at your own risk. Before submitting the exercise, restart the kernel and run the notebook from start to finish to make sure everything works.\n",
    "4. You are allowed to use functions and methods from the [Python Standard Library](https://docs.python.org/3/library/) and [numpy](https://www.numpy.org/devdocs/reference/) only. Any other imports are forbidden, unless been provided by us.\n",
    "4. Your code must run without errors. Note,  **Code that fail to  run will not be graded.**\n",
    "5. Document your code properly.\n",
    "5. Go over Basic.py and MoreOnBasic.py - you can find there relevant python functions that will make your life easier.\n",
    "\n",
    "## Honor Code:\n",
    "The assignment is a basic tool for learning the material. You can probably find the solution on the web, however, you will not learn what you should learn from it. In addition, since we give grades on the assignment, using existing solutions will be considered dishonest.\n",
    "In particular, you are not allowed to copy or use any code that solve the task. \n",
    "You are more than welcome to talk with your friends, but you are not allowed to give your code or answers and you are not allowed to use their code or answers. \n",
    "Remember – you take this course in order to learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "# specify the way plots behave in jupyter notebook\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.cmap'] = 'gray'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "print(\"Python version: \", platform.python_version())\n",
    "print(\"Numpy version: \", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:black\">Section A: Convolution (16 pt)\n",
    "In this part, you will need to write a function **convolvedImage = convolutionMask(img,mask)**  which gets a 2D np.array of an image and a convolution mask (Kernel) and output the convolved image with your mask. It also should plot  the original image and the convolved image side by side. Use captions on each image that indicates what you present. (Hint: see example in Additional_examples in Moodle)\\\n",
    "You may use the convolve2d function from scipy.signal.\\\n",
    "**Note:** Make sure that you understand the differences between correlation and convolution.\\\n",
    "Suggest a convolution mask for each of the 4 cases: \n",
    "    \n",
    "1. Mask1:  a convolution mask (kernel)  that computes the sum of a 3x5 pixels around each pixel (height 3 and width 5). \n",
    "   \n",
    "    \n",
    "2. Mask2:  a convolution mask (kernel) of size *5×5* such that the maximal value over all possible grey level images (range 0 to 255) will be obtained in the center of a widnow that contains a white non-symmetric   **'+'** shape region surrounded by black pixels (see the region below).  Note, the rest of the image may contain any values.\n",
    "\n",
    "    The  '+' shape region:\\\n",
    "    ``\n",
    "     0    0    0    0    0 \n",
    "    0    0   255   0    0 \n",
    "    0   255  255  255  255 \n",
    "    0    0   255   0    0 \n",
    "    0    0    0    0    0    ``\n",
    "     \n",
    "\n",
    "3. Let '*' be a don't care value.\\\n",
    "    Mask3:  a mask as defined in  2 above  but for the following region:\\\n",
    "    ``  \n",
    "    0    0     0    0    0\n",
    "    0    *    255   *    0\n",
    "    0   255   255  255  255\n",
    "    0    0    255   0    0\n",
    "    0    0     0    0    0\n",
    "      ``\n",
    "4. Maks 4: a convolution mask (kernel)  that computes a 2 pixel shift of the image to the left.\\\n",
    "    You can ignore the results along the border of the image.\n",
    "\n",
    "**Submit your function below and the masks and results either below or in the PDF file**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# This function will be part your functions' test - do not change it\n",
    "# You may add any helper function for your implementation and to write your code in the cell below\n",
    "\n",
    "def test_A(imageName):\n",
    "    img = cv2.imread(imageName, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    convolvedImage1 = convolutionMask(img,mask1)\n",
    "    \n",
    "    convolvedImage2 = convolutionMask(img,mask2)\n",
    "    \n",
    "    convolvedImage3 = convolutionMask(img,mask3)\n",
    "        \n",
    "    convolvedImage4 = convolutionMask(img,mask4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutionMask(img,mask):\n",
    "    # Your implementation\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masks:\n",
    "\n",
    "# mask1 = ...\n",
    "# mask2 = ...\n",
    "# mask3 = ...\n",
    "# mask4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = load your image here\n",
    "# test_A(img)\n",
    "\n",
    "# print and check your results - advicing you to check your code on trivial problems (toy problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:black\"> Section B: Edge Detector (50 pt)\n",
    "\n",
    "In this section, you will implement the classic Canny edge detector and Sobel edge detector, apply them and explore their paremeters. \n",
    "\n",
    "Reference: \n",
    "[F. J. Canny. A computational approach to edge detection. IEEE Trans. Pattern Analysis and Machine Intelligent (PAMI), 8(6):679-698, 1986.](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4767851&casa_token=-KErvLLfyjQAAAAA:-Q-efDIF1sM3mJBrQfCZnqaPYftS4IspVi_9NR7kfmdx8AnFFmKSy5HnRjk2PpHpNR0VUOsw-ML4fw)\n",
    "\n",
    "\n",
    "## <span style=\"color:black\"> **B1 - Implement Canny**  \n",
    "Write the function: **CannyEdges = Canny(img, sigma, L_th, H_th)**\n",
    "- The output is a binary image: 1 for an edge pixel and 0 for the rest.\n",
    "- Following are the function parameters:\n",
    "    - *img*: a 2D array  that contains a  grey-level image. \n",
    "    - *sigma*: the gaussian std. \n",
    "    - *L_th*, *H_th*: the Low and high threholds of the algorithm.\n",
    "\n",
    "Use the following steps:\n",
    "\n",
    "1. Compute two kernels with the derivative of a Gaussian: G_dx, G_dy  = Deriv_Gauss_xy(sigma).\\\n",
    "   **Note**:\\\n",
    "    (i) See an example of how to define a mask given a function in  'AddionalExamples.ipynb'.\\\n",
    "    (ii) The mask_size should be around 6$\\sigma$+1.\\\n",
    "    You can check and see if smaller or larger mask size affect the results.\n",
    "   **A question for thought (not for submission)**: what is the expected sum of the elements in the kernel? \n",
    "    \n",
    "2. Using these masks compute two matrixes, $I_x$ and $I_y$, with the derivatives of the image in the $x$ and in the $y$ directions, respectively:\\\n",
    "    **Ix, Iy = Grad_xy(img, sigma)**\n",
    "\n",
    "3. Compute two matrices *G_orientation* and *G_magnitute* with the gradient  orientation and magnitude at each pixel:\\\n",
    "    **G_orientation, G_magnitude = Grad_orient_mag(Ix,Iy)**\n",
    "\n",
    "4. Compute non-maximum suppression (thinning) into a matrix:\\\n",
    "    **G_thin = non_maximum_supression(G_magnitude, G_orientation)** \n",
    "\n",
    "    **Note**: For computing non-maximum suppression, edge orientation should be rounded to be one of four orientations:\n",
    "    Gradients that are approximately horizontal, approximately vertical, and approximately one of the diagonals (see figure). ![](NMS-orientation.jfif)\n",
    "\n",
    "5. Edge Tracking by Hysteresis: use the two thresholds, *L_th*, *H_th*, to put it all together and compute the canny edge detector. \\\n",
    "    The output should be a binary map where an edge pixel is 1 and the rest are 0:\\\n",
    "    **E = DoubleThreshold(L_th, H_th)** \\\n",
    "In order to get full credit, you will need to find an  **efficient vectorization code** (a single loop may be used only over edge pixels).  \n",
    "**Hint**: For efficient vectorized code of the DoubleThreshold, you may want to use: (i) image threshold function; (ii) dilate function ; (iii) add images; (iv)  the function cv2.connectedComponents(img, connectivity=8). See slides of Class 2.\n",
    "\n",
    "\n",
    "\n",
    "**Submit your functions and an example of one of the images**.\n",
    "\n",
    "The desire output should look like that: <img src=\"canny_example.png\" style=\"margin-left:auto; margin-right:auto\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Deriv_Gauss_xy(sigma):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section B\n",
    "\n",
    "def canny(imageName, sigma, L_th, H_th):\n",
    "    \n",
    "    G_dx, G_dy  = Deriv_Gauss_xy(sigma)\n",
    "        \n",
    "    img = cv2.imread(imageName, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    Ix, Iy = ex1.Grad_xy(img, sigma)\n",
    "    G_orientation, G_magnitude = Grad_orient_mag(Ix,Iy)\n",
    "    \n",
    "    \n",
    "    G_thin = non_maximum_supression(G_magnitude, G_orientation)\n",
    "    \n",
    "    E = DoubleThreshold(G_thin,L_th,H_th)\n",
    "    \n",
    "    return CannyEdges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:black\"> **B2 - Apply and explore**. \n",
    "In this part you will apply your Canny edge detector and explore its parameters \n",
    "\n",
    "1. Test your functions on an image you choose. Explore various parameters and choose a set such that the result  looks “good”.  \\\n",
    "    **Submit in the below or at the pdf file**: display the image you choosed, its edges, and the parameters you used.\n",
    "\n",
    "2. Explore with different sets of parameters **sigma ,L_th, H_th**. \n",
    "3. Assume you run the canny edge detector on the same image once with the set of parameters **sigma1 ,L_th1, H_th1** and once with the set of parameters **sigma2 ,L_th2, H_th2**. The obtained results are E1 and E2, respectively.\n",
    "Answer true or false, give a short explanation to your answer and give an example for each of the cases:\\\n",
    "   a. **True / False** When *sigma1 > sigma2*, *L_th1 = L_th2*, and *H_th1 = H_th2* - the location of the edges in E1 is more accurate than those in E2. \\\n",
    "   b. **True / False** When *sigma1 = sigma2*, *L_th1 > L_th2*, and *H_th1 = H_th2* - the edges in E1 are longer than in E2. \\\n",
    "   c. **True / False** When *sigma1 = sigma2*, *L_th1 = L_th2*, and *H_th1 < H_th2* - there are more edges in E1 than in E2. \\\n",
    "   d. **True / False** It is possible to find two sets *sigma1, L_th1, H_th1* and *sigma1, L_th1, H_th1* such that E1 has no edges while E2 contains edges.\n",
    "   \n",
    "4. Implement Sobel edge detector **SobelEdges = SobelEdge(img, th)**. \n",
    "5. Choose an image and a set of parameters for the Canny and for the Sobel edge detectors, that demostrate differences between the two edge maps. Explain what is the diffrence between the two esge maps. \n",
    "6. Theoretical question: explain which parts of the Canny algorithm, its implementation can be parallelized.    \n",
    "\n",
    "    **Submit below or in the pdf file**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section C:  Hough transform for detecting straight lines\n",
    "Hough Transform  (34 pt) \n",
    "\n",
    "In this section, you will learn how to find straight lines in an edge image using hough transform  [Duda and Hart, 1972](http://www.ai.sri.com/pubs/files/tn036-duda71.pdf). \n",
    "\n",
    "The basic idea is to use voting process for detecting all possible straight lines within the edge map of an image, despite outliers and imperfect straight lines. You can implement it yourself or use the implementation from  https://alyssaq.github.io/2014/understanding-hough-transform/ \\\n",
    "(Use the basic hough transform and not its extensions.)\n",
    "\n",
    "1. (7pt) Apply the hough transform to images: \"linesOnTheRoadGray.jpg\"\n",
    " <img src=\"linesOnTheRoadGray.jpg\" style=\"margin-left:auto; margin-right:auto; width: 200px;\"/>\n",
    "\n",
    "2. (10pt) Write a function that computes the  longest straight line in an image, and display it overlay on the original image.\\\n",
    "    **length = longest_straight_line(img, paramerts).** \n",
    "3. (10pt) Suggest an algorithm that detects the dashed and the solide road lines from a road image. Give a high level description of your algorithm.\\\n",
    "4. (7pt)Implement the algorithm you suggested in 3 and show its results on the given image. \n",
    "**Hint:** Pay attention to how many edges you expect on each part of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section C\n",
    "\n",
    "def longest_straight_line(img, Par):\n",
    "    # your implementation\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write here code that calls the function with your desire parameters and answer the open questions\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This code is for the TA - you might want to use it for your debugging\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #test A\n",
    "    imageName = './images/cameraman.jpg'\n",
    "    test_A(imageName)\n",
    "\n",
    "    synthName = './images/synthCheck.tif'\n",
    "    test_A(synthName)\n",
    "    \n",
    "    #test B\n",
    "    imageName = './images/Church.jpg'\n",
    "    sigma, L_th, H_th  = 1.3, 0.1 , 0.15\n",
    "    resultCanny = canny(imageName,sigma, L_th, H_th)\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
